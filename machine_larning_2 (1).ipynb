{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "machine_larning_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "acBquINaVwz_",
        "colab_type": "code",
        "outputId": "4cadb662-e585-4da4-f101-c7bed6a1c3ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2620
        }
      },
      "cell_type": "code",
      "source": [
        "# this file is a *skeleton* for a triplet-loss network for embedding\n",
        "# the MNIST digits.\n",
        "\n",
        "# source: https://github.com/Ao-Lee/Shares/blob/master/triplet%20inputs.py\n",
        "#\n",
        "# adapted (a lot!) by James McDermott:\n",
        "# - changed to MNIST task\n",
        "# - changed to a small, simple network (not ResNet)\n",
        "# - added generation of proper a, p, n triplets\n",
        "# - increased alpha to try to prevent the embedding from winning trivially\n",
        "# - removed the L2 normalisation (pushing all digits to surface of hypersphere)\n",
        "# - added a 2D layout visualisation of our embedding\n",
        "# (these comments apply to the full version, not the skeleton version provided here.)\n",
        "\n",
        "from keras.models import Model, Sequential\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dense, Dropout, Flatten, Convolution2D, MaxPooling2D\n",
        "from keras.layers import Input, Lambda\n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import load_model\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "drive.mount('/content/drive')\n",
        "!Is \"/content/drive/My Drive/Colab Notebooks\"\n",
        "buf = \"/content/drive/My Drive/Colab Notebooks/emnist_train_images_3.npy\"\n",
        "\n",
        "############## DATA ###########################\n",
        "# load and shape data as usual, but here we don't process class labels\n",
        "# to one-hot encoding. In fact, we don't exactly use class labels\n",
        "# during training, only while setting up the triplets.\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "def get_image(label, test=False):\n",
        "    \"\"\"Choose an image from our training or test data with the\n",
        "    given label.\"\"\"\n",
        "    if test:\n",
        "        y = y_test; X = X_test\n",
        "    else:\n",
        "        y = y_train; X = X_train\n",
        "    idx = np.random.randint(len(y))\n",
        "    while y[idx] != label:\n",
        "        # keep searching randomly!\n",
        "        idx = np.random.randint(len(y))\n",
        "    return X[idx]\n",
        "    \n",
        "def get_triplet(test=False):\n",
        "    \"\"\"Choose a triplet (anchor, positive, negative) of images\n",
        "    such that anchor and positive have the same label and\n",
        "    anchor and negative have different labels.\"\"\"\n",
        "    n = a = np.random.randint(10)\n",
        "    while n == a:\n",
        "        # keep searching randomly!\n",
        "        n = np.random.randint(10)\n",
        "    a, p = get_image(a, test), get_image(a, test)\n",
        "    n = get_image(n, test)\n",
        "    return a, p, n\n",
        "  \n",
        "def generate_triplets(test=False):\n",
        "    \"\"\"Generate an un-ending stream (ie a generator) of triplets for\n",
        "    training or test.\"\"\"\n",
        "    while True:\n",
        "        list_a = []\n",
        "        list_p = []\n",
        "        list_n = []\n",
        "        for i in range(batch_size):\n",
        "            a, p, n = get_triplet(test)\n",
        "            list_a.append(a)\n",
        "            list_p.append(p)\n",
        "            list_n.append(n)     \n",
        "        A = np.array(list_a, dtype='float32')\n",
        "        P = np.array(list_p, dtype='float32')\n",
        "        N = np.array(list_n, dtype='float32')\n",
        "        # a \"dummy\" label which will come in to our identity loss\n",
        "        # function below as y_true. We'll ignore it.\n",
        "        label = np.ones(batch_size) \n",
        "        yield [A, P, N], label   \n",
        "\n",
        "############## Loss ###########################\n",
        "def identity_loss(y_true, y_pred):\n",
        "    \"\"\"This loss function just takes the mean of y_pred. Because of the\n",
        "    way we wire the network (see complete_model below), y_pred is the\n",
        "    output of the triplet loss, so minimising it is what we want to\n",
        "    do.\"\"\"\n",
        "    return K.mean(y_pred)\n",
        "\n",
        "def triplet_loss(x):\n",
        "    \"\"\"The triplet loss is ||A - P|| - ||A - N|| + alpha, where ||.||\n",
        "    is the Euclidean norm. Notice that this is not a loss function in the\n",
        "    format expected by Keras, ie f(y_true, y_pred).\"\"\"\n",
        "    anchor, positive, negative = x\n",
        "    # XXX YOUR CODE HERE: CALCULATE loss. USE K.\n",
        "    p_dist = K.sqrt(K.sum(K.square(anchor-positive), axis=-1))\n",
        "    n_dist = K.sqrt(K.sum(K.square(anchor-negative), axis=-1))\n",
        "    loss =K.maximum(p_dist-n_dist+alpha,0)\n",
        "    return loss\n",
        "       \n",
        "############## Model ###########################\n",
        "def embedding_model():\n",
        "    \"\"\"A tiny model similar to the network we used for MNIST\n",
        "    classification. We assume the architecture should be good for\n",
        "    MNIST embedding. Its input is an image and output is an embedding,\n",
        "    not a classification, so the final layer is not a softmax. We\n",
        "    don't compile or add a loss since this will become a component in\n",
        "    the complete model below.\"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Convolution2D(32, (3, 3), activation='relu',input_shape=(28,28,1)))\n",
        "    model.add(Convolution2D(32, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(32))\n",
        "    return model\n",
        "\n",
        "def complete_model(base_model):\n",
        "    \"\"\"This part of the model is quite tricky. Rather than a Sequential\n",
        "    model, we declare a Model and say which are its inputs and\n",
        "    outputs, and we declare how the outputs are calculated from the\n",
        "    inputs. In particular, there are no layers in this model, *other\n",
        "    than* the layers in the embedding model discussed above.\n",
        "\n",
        "    A further complication is that our triplet loss can't be\n",
        "    calculated as a function of y_true and y_predicted as\n",
        "    usual. Instead we calculate the triplet loss as an extra Lambda\n",
        "    layer. Then the Model's loss is set to be equal to the triplet\n",
        "    loss via the identity function.\"\"\"\n",
        "    input_1 = Input((imsize, imsize, 1))\n",
        "    input_2 = Input((imsize, imsize, 1))\n",
        "    input_3 = Input((imsize, imsize, 1))\n",
        "    # call the base_model three times to get A, P, N\n",
        "    A=base_model(input_1)\n",
        "    P=base_model(input_2)\n",
        "    N=base_model(input_3)\n",
        "    # XXX YOUR CODE HERE.\n",
        "    loss = Lambda(triplet_loss)([A, P, N]) \n",
        "    model = Model(inputs=[input_1, input_2, input_3],outputs=loss)\n",
        "    model.compile(loss=identity_loss, optimizer=Adam(LR))\n",
        "    return model\n",
        "\n",
        "############## Settings ##########################\n",
        "imsize = 28\n",
        "# XXX you might like to play with some of these hyperparameters\n",
        "batch_size = 100\n",
        "# 2D is interesting for visualisation, but higher allows more \"space\"\n",
        "# to achieve accuracy in complex domains, eg 128 is common for\n",
        "# faces. but MNIST is simple, so maybe 2 is enough for us anyway.\n",
        "embedding_dim = 2 \n",
        "LR = 0.0001 # be careful: too large will be unstable for our data\n",
        "EPOCHS = 50\n",
        "alpha = 0.2 # interesting to think about different values\n",
        "############## Main ###############################\n",
        "# create the data generators\n",
        "train_generator = generate_triplets()\n",
        "test_generator = generate_triplets(test=True)\n",
        "# instantiate the model and take a look\n",
        "# XXX YOUR CODE HERE: create the embedding model and then use\n",
        "base_model=embedding_model()\n",
        "model=complete_model(base_model)\n",
        "# that to create the complete model\n",
        "print(model.summary())\n",
        "# fit\n",
        "# XXX YOUR CODE HERE: call fit_generator() to fit the model.\n",
        "H =model.fit_generator(train_generator,validation_data=test_generator,epochs=EPOCHS,steps_per_epoch=30,validation_steps=20)\n",
        "\n",
        "####################plot loss value##################################\n",
        "# plot the training loss and accuracy\n",
        "N = np.arange(0, EPOCHS)\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(N, H.history['loss'], label=\"train_loss\")\n",
        "plt.plot(N, H.history['val_loss'], label=\"val_loss\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "#plt.savefig(\"keras_mnist.png\")\n",
        "################# Visualisation ###################\n",
        "# we add an extra 28 pixels to allow for images whose bottom-left is\n",
        "# at the top or right border\n",
        "canvas_size = 4000\n",
        "canvas = np.zeros((canvas_size+imsize, canvas_size+imsize), dtype=float)\n",
        "def loc2pix(x, size):\n",
        "    \"\"\"All values in x are in [-1, 1], we want it in [0, size].\"\"\"\n",
        "    # add 1 to make it non-negative, squeeze to remove trivial\n",
        "    # dimension and transform.\n",
        "    x = (((1.0 + x.squeeze()) / 2) * size).astype(int)\n",
        "    assert np.all(x >= 0) and np.all(x < size)\n",
        "    return x\n",
        "for ib, batch in enumerate(test_generator):\n",
        "    APN, label = batch\n",
        "    for i in range(batch_size):\n",
        "        # get the embedding for a, p, n: each should be in [-1, 1]^2\n",
        "        # XXX YOUR CODE HERE. Set a to be the embedding of APN[0][i:i+1],\n",
        "        # and similarly p for APN[1][i:i+1] and n for APN[2][i:i+1].\n",
        "        # Think about what you need to call.\n",
        "        a=APN[0][i:i+1]\n",
        "        p=APN[1][i:i+1]\n",
        "        n=APN[2][i:i+1] \n",
        "        #A=model.predict([a,n,p])\n",
        "        #print(A)\n",
        "        a=base_model.predict(a)\n",
        "        p=base_model.predict(p)\n",
        "        n=base_model.predict(n)\n",
        "       \n",
        "        # transform a, p, n to pixel-space [0, 4028]^2\n",
        "        a = loc2pix(a, canvas_size)\n",
        "        p = loc2pix(p, canvas_size)\n",
        "        n = loc2pix(n, canvas_size)\n",
        "        # paint the image of each digit onto the canvas\n",
        "        canvas[a[0]:a[0]+imsize, a[1]:a[1]+imsize] = APN[0][i].squeeze()\n",
        "        canvas[p[0]:p[0]+imsize, p[1]:p[1]+imsize] = APN[1][i].squeeze()\n",
        "        canvas[n[0]:n[0]+imsize, n[1]:n[1]+imsize] = APN[2][i].squeeze()        \n",
        "    break # one batch of 100 samples is enough for visualisation    \n",
        "fig, ax = plt.subplots(figsize=(40, 40)) # we have to make it large to avoid subsampling\n",
        "ax.matshow(canvas)\n",
        "#plt.savefig(\"/content/drive/My Drive/Colab Notebooks/keras_mnist_triplet_layout8.png\")\n",
        "plt.close()\n",
        "\n",
        "#image recognize, I pick one image for digit 0-9 and the achor image is the letter image then\n",
        "#using basic model to obtain the embeddings and then get the minimal value of 9 image after caculate the \n",
        "#distance, then if the minial distance smaller than 0.5, print this digit, otherwise print unknow image\n",
        "#############################recognize function##########################################\n",
        "def image_recognize(base_model,test=True):  \n",
        "    X_new=np.load(buf)\n",
        "    X_new = X_new.reshape(X_new.shape[0], 28, 28, 1)\n",
        "    X_new = X_new.astype('float32')\n",
        "    X_new /= 255 \n",
        "    labels=[0,1,2,3,4,5,6,7,8,9]\n",
        "    for j in range(X_new.shape[0]):\n",
        "      min_similarity=1000\n",
        "      digit_label=11\n",
        "      for i in labels:\n",
        "        pos=get_image(i,test)\n",
        "        pos=pos.reshape(1,28,28,1)\n",
        "        arch=X_new[j]\n",
        "        arch=arch.reshape(1,28,28,1)   \n",
        "        arch=base_model.predict(arch)\n",
        "        pos=base_model.predict(pos)\n",
        "        A = tf.placeholder(\"float\")\n",
        "        P = tf.placeholder(\"float\")\n",
        "        p_dist = K.sqrt(K.sum(K.square(A-P), axis=-1))\n",
        "        sess = tf.Session()\n",
        "        dis=sess.run(p_dist, feed_dict={A: arch, P: pos})\n",
        "        if dis < min_similarity:\n",
        "            min_similarity=dis\n",
        "            digit_label=i\n",
        "        sess.close()  \n",
        "      if min_similarity<0.5:\n",
        "         print('this image is digit ',digit_label)\n",
        "      else:\n",
        "         print('unknown image')\n",
        "\n",
        "image_recognize(base_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/bin/bash: Is: command not found\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_70 (InputLayer)           (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_71 (InputLayer)           (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_72 (InputLayer)           (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_24 (Sequential)      (None, 32)           603648      input_70[0][0]                   \n",
            "                                                                 input_71[0][0]                   \n",
            "                                                                 input_72[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lambda_31 (Lambda)              (None,)              0           sequential_24[1][0]              \n",
            "                                                                 sequential_24[2][0]              \n",
            "                                                                 sequential_24[3][0]              \n",
            "==================================================================================================\n",
            "Total params: 603,648\n",
            "Trainable params: 603,648\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/50\n",
            "30/30 [==============================] - 7s 237ms/step - loss: 0.1813 - val_loss: 0.1058\n",
            "Epoch 2/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.1500 - val_loss: 0.0753\n",
            "Epoch 3/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.1258 - val_loss: 0.0615\n",
            "Epoch 4/50\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 0.1095 - val_loss: 0.0553\n",
            "Epoch 5/50\n",
            "30/30 [==============================] - 1s 40ms/step - loss: 0.0987 - val_loss: 0.0507\n",
            "Epoch 6/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0916 - val_loss: 0.0408\n",
            "Epoch 7/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0831 - val_loss: 0.0416\n",
            "Epoch 8/50\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 0.0815 - val_loss: 0.0363\n",
            "Epoch 9/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0751 - val_loss: 0.0337\n",
            "Epoch 10/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0769 - val_loss: 0.0323\n",
            "Epoch 11/50\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 0.0656 - val_loss: 0.0355\n",
            "Epoch 12/50\n",
            "30/30 [==============================] - 1s 40ms/step - loss: 0.0638 - val_loss: 0.0265\n",
            "Epoch 13/50\n",
            "30/30 [==============================] - 1s 41ms/step - loss: 0.0589 - val_loss: 0.0316\n",
            "Epoch 14/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 0.0624 - val_loss: 0.0263\n",
            "Epoch 15/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0552 - val_loss: 0.0269\n",
            "Epoch 16/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0525 - val_loss: 0.0221\n",
            "Epoch 17/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0538 - val_loss: 0.0256\n",
            "Epoch 18/50\n",
            "30/30 [==============================] - 1s 40ms/step - loss: 0.0514 - val_loss: 0.0182\n",
            "Epoch 19/50\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 0.0491 - val_loss: 0.0192\n",
            "Epoch 20/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 0.0440 - val_loss: 0.0229\n",
            "Epoch 21/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0438 - val_loss: 0.0211\n",
            "Epoch 22/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 0.0479 - val_loss: 0.0181\n",
            "Epoch 23/50\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 0.0417 - val_loss: 0.0166\n",
            "Epoch 24/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0397 - val_loss: 0.0191\n",
            "Epoch 25/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0395 - val_loss: 0.0157\n",
            "Epoch 26/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 0.0380 - val_loss: 0.0138\n",
            "Epoch 27/50\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 0.0380 - val_loss: 0.0126\n",
            "Epoch 28/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0406 - val_loss: 0.0148\n",
            "Epoch 29/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 0.0404 - val_loss: 0.0125\n",
            "Epoch 30/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 0.0321 - val_loss: 0.0137\n",
            "Epoch 31/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0367 - val_loss: 0.0117\n",
            "Epoch 32/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 0.0347 - val_loss: 0.0101\n",
            "Epoch 33/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 0.0352 - val_loss: 0.0111\n",
            "Epoch 34/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 0.0317 - val_loss: 0.0119\n",
            "Epoch 35/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0315 - val_loss: 0.0139\n",
            "Epoch 36/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 0.0326 - val_loss: 0.0100\n",
            "Epoch 37/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0346 - val_loss: 0.0100\n",
            "Epoch 38/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 0.0312 - val_loss: 0.0112\n",
            "Epoch 39/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0300 - val_loss: 0.0087\n",
            "Epoch 40/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0278 - val_loss: 0.0094\n",
            "Epoch 41/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 0.0302 - val_loss: 0.0097\n",
            "Epoch 42/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0281 - val_loss: 0.0110\n",
            "Epoch 43/50\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 0.0269 - val_loss: 0.0108\n",
            "Epoch 44/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 0.0284 - val_loss: 0.0081\n",
            "Epoch 45/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 0.0231 - val_loss: 0.0083\n",
            "Epoch 46/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 0.0261 - val_loss: 0.0082\n",
            "Epoch 47/50\n",
            "30/30 [==============================] - 1s 41ms/step - loss: 0.0241 - val_loss: 0.0071\n",
            "Epoch 48/50\n",
            "30/30 [==============================] - 1s 43ms/step - loss: 0.0234 - val_loss: 0.0116\n",
            "Epoch 49/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0263 - val_loss: 0.0088\n",
            "Epoch 50/50\n",
            "30/30 [==============================] - 1s 42ms/step - loss: 0.0256 - val_loss: 0.0093\n",
            "unknown image\n",
            "unknown image\n",
            "unknown image\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAFaCAYAAAAU1YTeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "LI0DqrCIkt-K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from pandas import Series,DataFrame\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import os \n",
        "import keras\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.layers.convolutional import Convolution2D,ZeroPadding2D,MaxPooling2D\n",
        "from keras.layers import Lambda, Dense,Dropout,Flatten,Activation\n",
        "from keras.models import Sequential, model_from_json\n",
        "from keras.preprocessing.image import image\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications import imagenet_utils\n",
        "from keras.models import Sequential,Model\n",
        "\n",
        "# use pre-taining model\n",
        "model = Sequential()\n",
        "model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
        "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        " \n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        " \n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        " \n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        " \n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(ZeroPadding2D((1,1)))\n",
        "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        " \n",
        "model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Convolution2D(2622, (1, 1)))\n",
        "model.add(Flatten())\n",
        "model.add(Activation('softmax'))\n",
        "# the path of the download weights\n",
        "model.load_weights('/content/drive/My Drive/Colab Notebooks/face_face/vgg_face_weights.h5')\n",
        "\n",
        "\n",
        "# get the embedding layer of VGG\n",
        "vgg_face_descriptor = Model(inputs=model.layers[0].input, outputs=model.layers[-2].output)\n",
        "vgg_face_descriptor.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6uVFbtC2k4Lp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "!Is \"/content/drive/My Drive/Colab Notebooks\"\n",
        "list_image = []\n",
        "dic_image = {}\n",
        "index = 0\n",
        "key_index =[]\n",
        "# read all the image \n",
        "for filename in os.listdir(r\"/content/drive/My Drive/Colab Notebooks/face\"): \n",
        "    # use loop to read all images \n",
        "    filename = \"/content/drive/My Drive/Colab Notebooks/face/\"+filename\\\n",
        "    # convert the image to size (224,224)     \n",
        "    original = load_img(filename, target_size=(224, 224))\n",
        "    dic_image[index] = original\n",
        "    index = index+1\n",
        "    # convert image to array\n",
        "    numpy_image = img_to_array(original)\n",
        "    image_batch = np.expand_dims(numpy_image, axis=0)\n",
        "    # preprocess_input to process the image array into  model which suits VGG\n",
        "    processed_image = imagenet_utils.preprocess_input(image_batch)\n",
        "    # use predict function to get embedding layer\n",
        "    predictions = vgg_face_descriptor.predict(processed_image)\n",
        "    # add embedding layer into a list\n",
        "    list_image.append(predictions[0])\n",
        "    key_index.append(index)\n",
        " \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3cD_5ZL7k_iA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt  \n",
        "import numpy as np  \n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn import datasets  \n",
        "from sklearn.datasets import load_iris \n",
        "from operator import itemgetter\n",
        "import cv2\n",
        "from pylab import *\n",
        "\n",
        "# use K-mean to make classification\n",
        "estimator = KMeans(n_clusters=3)\n",
        "estimator.fit(list_image)\n",
        "# classification cluster\n",
        "label_pred = estimator.labels_ \n",
        "# get specific cluster\n",
        "# \"number\" is to visualize how mang pictures\n",
        "def show_cluster(cluster,number,label_pred,list_image):\n",
        "    list_cluster= []\n",
        "    image_list_index= []\n",
        "    for i in range(len(label_pred)):\n",
        "        if label_pred[i] == cluster:\n",
        "           list_cluster.append(label_pred[i])\n",
        "           image_list_index.append(i)\n",
        "    plt.figure()\n",
        "    print(\"this is cluster\",cluster)\n",
        "    for v in range(len(image_list_index[0:number])):\n",
        "        j = v +1\n",
        "        image = dic_image[image_list_index[0:number][v]]\n",
        "        plt.subplot(4,8,j)\n",
        "        plt.rcParams[\"axes.grid\"]=False\n",
        "        plt.imshow(image)\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "show_cluster(0,4,label_pred,list_image)  \n",
        "show_cluster(1,4,label_pred,list_image) \n",
        "show_cluster(2,4,label_pred,list_image) \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}